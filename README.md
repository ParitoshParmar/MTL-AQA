# MTL-AQA
[What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment](https://arxiv.org/abs/1904.04346)

<b>***</b> <i>Want to know the score of a Dive at the ongoing Olympics, even before the judges' decision?</i> <b>Try out our [AI Olympics Judge](https://share.streamlit.io/gitskim/aqa_streamlit/main/main.py) ***</b>


## MTL-AQA Concept:

<p align="center"> <img src="diving_sample.gif?raw=true" alt="diving_video" width="200"/> </p>
<p align="center"> <img src="mtlaqa_concept.png?raw=true" alt="mtl_net" width="400"/> </p>


This repository contains MTL-AQA dataset + code introduced in the above paper. If you find this dataset or code useful, please consider citing:
```
@inproceedings{mtlaqa,
  title={What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment},
  author={Parmar, Paritosh and Tran Morris, Brendan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={304--313},
  year={2019}
}
```

## Check out our other relevant works:

[Fine-grained Exercise Action Quality Assessment](https://github.com/ParitoshParmar/Fitness-AQA): Self-Supervised Pose-Motion Contrastive Approaches for Fine-grained Action Quality Assessment (can be used for Diving as well!) + Fitness-AQA dataset
